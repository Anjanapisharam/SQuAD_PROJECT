{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import collections\n",
    "import numpy as np\n",
    "from spacy.en import English\n",
    "import string\n",
    "import unicodedata\n",
    "import gensim\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from scipy.spatial import distance\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "parser = English()\n",
    "\n",
    "\n",
    "sqd_data = pd.read_json(\"/home/anjana/Downloads/train-v1.1.json\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('/home/anjana/Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "qtntype_list = ['why','how', 'what', 'when','which', 'who','whom', 'where','whose']\n",
    "pun_list = list(string.punctuation)\n",
    "delelements_list = stopword + qtntype_list + pun_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_all(repls, str):\n",
    "   # return re.sub('|'.join(repls.keys()), lambda k: repls[k.group(0)], str)                                    \n",
    "   return re.sub('|'.join(re.escape(key) for key in repls.keys()),\n",
    "                 lambda k: repls[k.group(0)], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_question(para_question):\n",
    "    question_list = []\n",
    "    for i in range(len(para_question)):\n",
    "        l1 = para_question[i]['question']\n",
    "        l1 = unicodedata.normalize('NFKD', l1).encode('ascii','ignore').decode('utf-8')\n",
    "        question_list.append(l1)\n",
    "    \n",
    "    #Appropriate question type replacement\n",
    "    Question_list = []\n",
    "    for i in range(len(question_list)):\n",
    "        Question_list.append(replace_all({\"how\": \"how\", \"when\": \"when\",\"what\": \"what\",\"whom\": \"whom\",\"which\": \"which\", \"where\": \"where\", \"who\":\"who\" ,\"whose\":\"whose\"}, question_list[i]))\n",
    "        \n",
    "    return Question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(para_context):\n",
    "\n",
    "    context = unicodedata.normalize('NFKD', para_context).encode('ascii','ignore').decode('utf-8')\n",
    "    #print(context)\n",
    "    #sentence_tokeniztion\n",
    "    senttokenized_context = sent_tokenize(context)\n",
    "    sentencelist = []\n",
    "    for sent_token in senttokenized_context:\n",
    "        sentencelist.append(sent_token) \n",
    "    \n",
    "    sentence_list = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "    for i in sentencelist:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        words = ([x.lower() for x in words])\n",
    "        words = ([x for x in words if x not in delelements_list])\n",
    "        words = [lemmatizer.lemmatize(x) for x in words]\n",
    "        words = [[s.encode('ascii').decode('utf-8') for s in words]]\n",
    "        sentence_list.append(words)\n",
    "    return sentencelist, sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_type_extractor(question_mapping):\n",
    "    Question_mapping = []\n",
    "    for i in range(len(question_mapping)):\n",
    "        if question_mapping[i] != 'how many' and question_mapping[i] != 'how much':\n",
    "            Question_mapping.append(question_mapping[i].split()[0])\n",
    "        else:\n",
    "             Question_mapping.append(question_mapping[i])\n",
    "    return Question_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmd_que_ans_pair(que_list, sen_list):\n",
    "    wmd_matrix = np.zeros([len(que_list),len(sen_list)]) \n",
    "    for i in range(len(que_list)):\n",
    "        for j in range(len(sen_list)):\n",
    "            wmd_matrix[i,j] =  word2vec_model.wmdistance(que_list[i],sen_list[j])  \n",
    "    wmd_df = pd.DataFrame(wmd_matrix)\n",
    "    wmd_df['sentence'] = wmd_df.T.idxmin()\n",
    "    wmd_df['qnno'] = wmd_df.index\n",
    "    que_no_ans_sen_no = []\n",
    "    for i in range(len(wmd_df)):\n",
    "        que_no_ans_sen_no.append([wmd_df['qnno'][i], wmd_df['sentence'][i]])\n",
    "    qn_sentence = []\n",
    "    for i in range(len(que_no_ans_sen_no)):\n",
    "        if que_no_ans_sen_no[i][0] == que_list.index(que_list[i]):\n",
    "            qn_sentence.append(que_list[i])\n",
    "    an_sentence = []\n",
    "    for i in range(len(que_no_ans_sen_no)):\n",
    "        for j in range(len(sen_list)):\n",
    "            if que_no_ans_sen_no[i][1] == sen_list.index(sen_list[j]):\n",
    "                an_sentence.append(sen_list[j]) \n",
    "    return qn_sentence, an_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def que_ner_ans_ner(que_sentence, ans_sentence):\n",
    "    ans_sentence_mapping = []\n",
    "    for i in range(len(ans_sentence)):\n",
    "        doc_ans = nlp(ans_sentence[i])\n",
    "        for ent in doc_ans.ents:\n",
    "            ans_sentence_mapping.append([i,ent.label_])\n",
    "\n",
    "    que_sentence_mapping = []\n",
    "    for i in range(len(que_sentence)):\n",
    "        doc_que = nlp(que_sentence[i])\n",
    "        for ent in doc_que.ents:\n",
    "            que_sentence_mapping.append([i,ent.label_])\n",
    "    return que_sentence_mapping, ans_sentence_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def que_df_ans_df(que_sen_map, ans_sen_map):\n",
    "    qno_anstag_df = pd.DataFrame(ans_sen_map,columns = ['QuestionNo','AnswerTag'])\n",
    "    qno_quetag_df = pd.DataFrame(que_sen_map, columns = ['QuestionNo', 'QuestionTag'])\n",
    "    return qno_quetag_df, qno_anstag_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def que_ans_combo_(questionword, answerword):\n",
    "    ques_ans_combo = []\n",
    "    for i in range(len(questionword)):\n",
    "        for j in range(len(answerword)):\n",
    "            ques_ans_combo.append([questionword[i],answerword[j]])\n",
    "    return(ques_ans_combo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_type(process_que_list):\n",
    "    question_mapping = [] \n",
    "    for i in range(len(process_que_list)):\n",
    "        l2 = nltk.word_tokenize(process_que_list[i])\n",
    "        #print(len(l2))\n",
    "        #print(l2)\n",
    "        missed = l2[-1]        \n",
    "        if missed == '?':\n",
    "            for j in range(len(l2)):\n",
    "\n",
    "\n",
    "                if l2[j] in qtntype_list:\n",
    "                    combine_list = l2[j]+\" \"+l2[j+1]\n",
    "                    question_mapping.append(combine_list)\n",
    "\n",
    "        else:\n",
    "\n",
    "             for k in range(len(l2)):#8\n",
    "\n",
    "                if k < len(l2)-1:  #7        \n",
    "\n",
    "                    if l2[k] in qtntype_list:\n",
    "                        combine_list = l2[k]+\" \"+l2[k+1]\n",
    "                        question_mapping.append(combine_list) \n",
    "                else:\n",
    "\n",
    "                        if l2[k] in qtntype_list:\n",
    "                            combine_list = l2[k]+\" \"+'abc'\n",
    "                            question_mapping.append(combine_list) \n",
    "    return question_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qntypefun(qnlist):\n",
    "    punc=set(\",./;'?&-\")\n",
    "\n",
    "    common_list = []\n",
    "    for i in qnlist:\n",
    "        list1 = (i.lower().split())\n",
    "        list2 = list(set(list1).intersection(qtntype_list)) \n",
    "        for j in list2:\n",
    "            strp =''.join(c for c in j if not c in punc)\n",
    "            common_list.append(strp) \n",
    "        if list2 == []:\n",
    "            common_list.append('others')\n",
    "        \n",
    "        \n",
    "    return common_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  385,   360,    12,    81,     8,    29,    30,    21,   421,\n",
       "           26,    13,    11,    65,   230,   577,   589],\n",
       "       [ 3047,  2574,   259,   774,    76,   234,   264,   113,  4630,\n",
       "          224,   722,   653,   777,  6862,  5670,  5829],\n",
       "       [19765, 15133,  1416,  4367,   435,  1246,  1979,   791, 18870,\n",
       "          622,  2112,   827,  3896, 12288, 28041, 31681],\n",
       "       [ 3206,  2266,   182,   570,    58,   257,   302,    84,  4718,\n",
       "          102,    56,    84,   810,  1659,  4272,  4559],\n",
       "       [ 1959,  1188,   291,   536,    35,   105,   140,    40,  1371,\n",
       "           31,    39,    35,   389,   947,  3366,  2944],\n",
       "       [ 8106,  3404,   230,   673,    90,   286,   513,   102,  4063,\n",
       "           92,    88,   102,   955,  1903,  5250,  6888],\n",
       "       [ 3886,  2290,   338,   835,    92,   199,   369,   104,  2779,\n",
       "           84,   145,   130,   671,  1749,  4917,  5023],\n",
       "       [  201,    79,     8,    13,     1,    13,     4,     3,   111,\n",
       "            1,     1,     1,    22,    38,   149,   182],\n",
       "       [  277,   124,     7,    10,     4,    14,    17,     7,   104,\n",
       "            4,     1,     1,    21,    55,   160,   195],\n",
       "       [ 1556,  1336,    85,   295,    44,    55,   143,    98,  1041,\n",
       "           44,    75,    40,   244,   980,  1982,  2255],\n",
       "       [20297,  4444,   501,  1167,   160,   406,  1106,   235,  7623,\n",
       "          216,   202,   233,  1461,  3887,  8679, 10094],\n",
       "       [ 4826, 12972,   219,  1370,   114,   356,   440,   422,  4416,\n",
       "           96,   717,   134,   862,  2910,  8612,  6128],\n",
       "       [  448,   200,   526,   164,     4,    29,    40,     3,   325,\n",
       "           11,    19,    26,    97,   274,   577,   590],\n",
       "       [  998,  1086,   140,  1575,    28,    93,    96,    39,  1052,\n",
       "           31,    45,    38,   216,   768,  2323,  1726],\n",
       "       [  183,    75,     8,    23,    55,    10,    21,     7,   154,\n",
       "            4,    12,    10,    27,   106,   174,   262],\n",
       "       [  325,   366,    23,   110,    10,   347,    38,     8,   451,\n",
       "            6,    10,    10,   106,   264,   630,   562],\n",
       "       [  738,   192,    30,    76,    13,    45,   439,    20,   503,\n",
       "            9,    18,    16,    96,   271,   460,   692],\n",
       "       [  221,   467,    15,    58,     7,     3,    43,   267,   162,\n",
       "           16,    21,     1,    43,    86,   321,   261],\n",
       "       [ 6261,  3749,   380,  1022,   123,   555,   667,   159, 13636,\n",
       "          287,  1246,   739,  1420,  5908,  8352,  9459],\n",
       "       [   83,    35,     4,     8,     2,     0,    12,     5,   130,\n",
       "          143,    11,     7,    16,   116,    77,   117],\n",
       "       [   29,    46,     4,     5,     1,     2,     1,     4,    90,\n",
       "            0,   217,    15,     6,    88,    75,   102],\n",
       "       [   50,    18,     6,     5,     1,     1,     7,     0,    95,\n",
       "            5,    12,    91,    11,    48,    65,    91],\n",
       "       [ 1957,  1102,   171,   360,    34,   134,   216,    61,  2204,\n",
       "           46,    58,    54,  1989,  1154,  2158,  2477],\n",
       "       [ 2047,  1339,   177,   374,    59,   141,   233,    50,  2151,\n",
       "          108,   219,   141,   497,  4022,  2780,  3284],\n",
       "       [ 9713,  9242,   925,  3068,   214,   811,   722,   341, 11138,\n",
       "          293,  1201,   644,  2277,  7867, 31181, 15560],\n",
       "       [10946,  5588,   870,  1820,   296,   666,  1122,   269, 11528,\n",
       "          305,   587,   658,  2255,  6909, 13495, 30647]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occ_matrix_df = pd.read_csv(\"/home/anjana/co_occ_matrix_final\", header=0, index_col=0)\n",
    "co_occ_matrix = co_occ_matrix_df.values\n",
    "co_occ_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_list = ['why','how','what','when','where','who', 'which','whom','whose','others','PERSON',\n",
    "          'NORP', 'FAC','LOC','PRODUCT', 'EVENT','WORK_OF_ART','LANGUAGE' ,'DATE' ,\n",
    "          'TIME' ,'PERCENT' ,'MONEY' ,'ORDINAL','CARDINAL','GPE', 'ORG']\n",
    "\n",
    "\n",
    "column_list = ['PERSON','NORP', 'FAC','LOC','PRODUCT', 'EVENT','WORK_OF_ART','LANGUAGE' ,'DATE' ,\n",
    "               'TIME' ,'PERCENT' ,'MONEY' ,'ORDINAL','CARDINAL','GPE','ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anjana/nltk/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "co_occ_matrix_df['Tags'] = co_occ_matrix_df.index\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "normed_matrix = normalize(co_occ_matrix, axis=1, norm='l1') \n",
    "normed_matrix_df = pd.DataFrame(normed_matrix, index = row_list, columns= column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.134710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.093158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.137765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.138279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.146020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tags variable     value\n",
       "0    why   PERSON  0.134710\n",
       "1    how   PERSON  0.093158\n",
       "2   what   PERSON  0.137765\n",
       "3   when   PERSON  0.138279\n",
       "4  where   PERSON  0.146020"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_matrix_df['Tags'] = normed_matrix_df.index\n",
    "\n",
    "#normalized heatmap\n",
    "melt_normed_matrix_df = pd.melt(normed_matrix_df,id_vars = ['Tags'])\n",
    "melt_normed_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_normed_matrix  = 1 - normed_matrix\n",
    "new_normed_matrix_df = pd.DataFrame(new_normed_matrix, index = row_list, columns= column_list)\n",
    "new_normed_matrix_df['Tags'] = new_normed_matrix_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.865290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.906842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.862235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.861721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>0.853980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tags variable     value\n",
       "0    why   PERSON  0.865290\n",
       "1    how   PERSON  0.906842\n",
       "2   what   PERSON  0.862235\n",
       "3   when   PERSON  0.861721\n",
       "4  where   PERSON  0.853980"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_new_normed_matrix_df = pd.melt(new_normed_matrix_df,id_vars = ['Tags'])\n",
    "melt_new_normed_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_dict = {'LOC': 1,'PERSON': 2,'NORP': 3,'FAC': 4,'PRODUCT': 5,'EVENT': 6,'WORK_OF_ART': 7,'LANGUAGE': 8,'DATE':9,'TIME': 10,'PERCENT': 11,'MONEY': 12,'ORDINAL': 13,'CARDINAL': 14,'GPE': 15, 'ORG': 16}\n",
    "question_dict = {'LOC': 10,\n",
    "                 'PERSON': 20,\n",
    "                 'NORP': 30,\n",
    "                 'FAC': 40,\n",
    "                 'PRODUCT': 50,\n",
    "                 'EVENT':60,\n",
    "                 'WORK_OF_ART':70,\n",
    "                 'LANGUAGE':80,\n",
    "                 'DATE': 90,\n",
    "                 'TIME': 100,\n",
    "                 'PERCENT': 110,\n",
    "                 'MONEY': 120,\n",
    "                 'ORDINAL':130,\n",
    "                 'CARDINAL': 140,\n",
    "                 'GPE': 150,\n",
    "                 'ORG': 160,\n",
    "                 \n",
    "                 'what': 170,\n",
    "                 'when': 180,\n",
    "                 'where': 190,\n",
    "                 'who': 200,\n",
    "                 'which':210,\n",
    "                 'whom': 220,\n",
    "                'whose': 230,\n",
    "                'how':240,\n",
    "                'why':250,\n",
    "                'others':260}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "melt_new_normed_matrix_df_1 = melt_new_normed_matrix_df.copy()\n",
    "melt_new_normed_matrix_df_1[\"Tags\"].replace(question_dict, inplace=True)\n",
    "melt_new_normed_matrix_df_1['variable'].replace(answer_dict, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy, Reader\n",
    "reader_new = Reader(line_format='user item rating', sep='\\t', rating_scale=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file_1 = melt_new_normed_matrix_df_1.to_csv(\"new_melt.txt\", sep= '\\t', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.dataset.DatasetAutoFolds object at 0x7f4baecda8d0>\n"
     ]
    }
   ],
   "source": [
    "reader_new = Reader(line_format='user item rating', sep='\\t', rating_scale=(0,1))\n",
    "melt_1 = Dataset.load_from_file(\"/home/anjana/new_melt.txt\", reader_new)\n",
    "print(melt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.94047868429\n",
      "1 0.940502403557\n",
      "2 0.939969831526\n",
      "3 0.940617119208\n",
      "4 0.940254271648\n",
      "5 0.940037478996\n",
      "6 0.940585729432\n",
      "7 0.941123111524\n",
      "8 0.942635811164\n",
      "9 0.940156000007\n",
      "10 0.940718699098\n",
      "11 0.942493776307\n",
      "12 0.943147165273\n",
      "13 0.94124648593\n",
      "14 0.941427995474\n",
      "15 0.938654270509\n",
      "16 0.939956597446\n",
      "17 0.93720426279\n",
      "18 0.942888098849\n",
      "19 0.941068892567\n"
     ]
    }
   ],
   "source": [
    "reconstruction_error_1 = []\n",
    "for i in range(20):\n",
    "    \n",
    "    algo = SVDpp(n_factors=i)\n",
    "    \n",
    "    for trainset, testset in melt_1.folds():\n",
    "        algo.train(trainset)\n",
    "        predictions_svdpp = algo.test(testset)\n",
    "        \n",
    "    \n",
    "    reconstruct = np.dot(algo.pu, algo.qi.T)\n",
    "    rmse = mean_squared_error(new_normed_matrix, reconstruct)**0.5\n",
    "    reconstruction_error_1.append(rmse)\n",
    "    print(i, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algo = SVDpp(n_factors=10)\n",
    "    \n",
    "for trainset, testset in melt_1.folds():\n",
    "    algo.train(trainset)\n",
    "    predictions_svdpp = algo.test(testset)\n",
    "    svdpp_df = pd.DataFrame(predictions_svdpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>-0.003996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>0.890518</td>\n",
       "      <td>0.937567</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>-0.047050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994778</td>\n",
       "      <td>0.976835</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0.017943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>-0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>8</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.945261</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "      <td>0.050435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid iid      r_ui       est                    details     error\n",
       "0  230   5  0.996004  1.000000  {'was_impossible': False} -0.003996\n",
       "1   90  14  0.890518  0.937567  {'was_impossible': False} -0.047050\n",
       "2  100   4  0.994778  0.976835  {'was_impossible': False}  0.017943\n",
       "3   70  11  0.995025  1.000000  {'was_impossible': False} -0.004975\n",
       "4  130   8  0.995697  0.945261  {'was_impossible': False}  0.050435"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdpp_df['error'] = svdpp_df.r_ui - svdpp_df.est #error =  observed - estimated\n",
    "svdpp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruct = np.dot(algo.pu, algo.qi.T) #reconstructed matrix\n",
    "rmse = mean_squared_error(new_normed_matrix, reconstruct)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruct_error = new_normed_matrix - reconstruct\n",
    "reconstruct_error_df = pd.DataFrame(reconstruct_error,index = row_list,columns = column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_column_list =['why',\n",
    " \n",
    "  'how',\n",
    " 'whose',               \n",
    " 'what',\n",
    " 'when',\n",
    " 'where',\n",
    " 'who',\n",
    " 'which',\n",
    " 'whom',\n",
    "'others',\n",
    "                \n",
    "                  \n",
    " 'q_PERSON',\n",
    " 'q_NORP',\n",
    " 'q_FAC',\n",
    " 'q_LOC',\n",
    " 'q_PRODUCT',\n",
    " 'q_EVENT',\n",
    " 'q_WORK_OF_ART',\n",
    " 'q_LANGUAGE',\n",
    " 'q_DATE',\n",
    " 'q_TIME',\n",
    " 'q_PERCENT',\n",
    " 'q_MONEY',\n",
    " 'q_ORDINAL',\n",
    " 'q_CARDINAL',\n",
    " 'q_GPE',\n",
    " 'q_ORG',\n",
    " 'a_PERSON',\n",
    " 'a_NORP',\n",
    " 'a_FAC',\n",
    " 'a_LOC',\n",
    " 'a_PRODUCT',\n",
    " 'a_EVENT',\n",
    " 'a_WORK_OF_ART',\n",
    " 'a_LANGUAGE',\n",
    " 'a_DATE',\n",
    " 'a_TIME',\n",
    " 'a_PERCENT',\n",
    " 'a_MONEY',\n",
    " 'a_ORDINAL',\n",
    " 'a_CARDINAL',\n",
    " 'a_GPE',\n",
    " 'a_ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn_ans_list = list(algo.pu) + list(algo.qi)\n",
    "qn_ans_list\n",
    "\n",
    "qn_ans_list_copy = qn_ans_list.copy()\n",
    "len(qn_ans_list_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_answer_dis = np.zeros((len(row_column_list), len(row_column_list))) \n",
    "\n",
    "for i in range(len(qn_ans_list)):\n",
    "    for j in range(len(qn_ans_list_copy)):\n",
    "        question_answer_dis[i,j] = distance.euclidean(qn_ans_list[i],qn_ans_list_copy[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>why</th>\n",
       "      <th>how</th>\n",
       "      <th>whose</th>\n",
       "      <th>what</th>\n",
       "      <th>when</th>\n",
       "      <th>where</th>\n",
       "      <th>who</th>\n",
       "      <th>which</th>\n",
       "      <th>whom</th>\n",
       "      <th>others</th>\n",
       "      <th>...</th>\n",
       "      <th>a_WORK_OF_ART</th>\n",
       "      <th>a_LANGUAGE</th>\n",
       "      <th>a_DATE</th>\n",
       "      <th>a_TIME</th>\n",
       "      <th>a_PERCENT</th>\n",
       "      <th>a_MONEY</th>\n",
       "      <th>a_ORDINAL</th>\n",
       "      <th>a_CARDINAL</th>\n",
       "      <th>a_GPE</th>\n",
       "      <th>a_ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>why</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369390</td>\n",
       "      <td>0.363307</td>\n",
       "      <td>0.283515</td>\n",
       "      <td>0.368420</td>\n",
       "      <td>0.370810</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.260210</td>\n",
       "      <td>0.343792</td>\n",
       "      <td>0.259073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391371</td>\n",
       "      <td>0.374754</td>\n",
       "      <td>0.328225</td>\n",
       "      <td>0.297465</td>\n",
       "      <td>0.336358</td>\n",
       "      <td>0.310173</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.357638</td>\n",
       "      <td>0.261070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>0.369390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>0.465410</td>\n",
       "      <td>0.489510</td>\n",
       "      <td>0.289396</td>\n",
       "      <td>0.322319</td>\n",
       "      <td>0.455112</td>\n",
       "      <td>0.410958</td>\n",
       "      <td>0.314226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445512</td>\n",
       "      <td>0.387252</td>\n",
       "      <td>0.544785</td>\n",
       "      <td>0.459130</td>\n",
       "      <td>0.497970</td>\n",
       "      <td>0.425309</td>\n",
       "      <td>0.426977</td>\n",
       "      <td>0.493475</td>\n",
       "      <td>0.411387</td>\n",
       "      <td>0.421921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whose</th>\n",
       "      <td>0.363307</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573273</td>\n",
       "      <td>0.484266</td>\n",
       "      <td>0.402513</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.415099</td>\n",
       "      <td>0.386007</td>\n",
       "      <td>0.401284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412578</td>\n",
       "      <td>0.507149</td>\n",
       "      <td>0.595443</td>\n",
       "      <td>0.521874</td>\n",
       "      <td>0.580396</td>\n",
       "      <td>0.543716</td>\n",
       "      <td>0.324952</td>\n",
       "      <td>0.454619</td>\n",
       "      <td>0.434054</td>\n",
       "      <td>0.357629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>0.283515</td>\n",
       "      <td>0.465410</td>\n",
       "      <td>0.573273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490411</td>\n",
       "      <td>0.526640</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.352533</td>\n",
       "      <td>0.510801</td>\n",
       "      <td>0.305893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562173</td>\n",
       "      <td>0.351014</td>\n",
       "      <td>0.359026</td>\n",
       "      <td>0.375087</td>\n",
       "      <td>0.320718</td>\n",
       "      <td>0.363193</td>\n",
       "      <td>0.440069</td>\n",
       "      <td>0.468581</td>\n",
       "      <td>0.506385</td>\n",
       "      <td>0.445194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>when</th>\n",
       "      <td>0.368420</td>\n",
       "      <td>0.489510</td>\n",
       "      <td>0.484266</td>\n",
       "      <td>0.490411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404092</td>\n",
       "      <td>0.310591</td>\n",
       "      <td>0.381433</td>\n",
       "      <td>0.454696</td>\n",
       "      <td>0.369421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472915</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.231219</td>\n",
       "      <td>0.316996</td>\n",
       "      <td>0.532049</td>\n",
       "      <td>0.367383</td>\n",
       "      <td>0.294792</td>\n",
       "      <td>0.375615</td>\n",
       "      <td>0.342236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.370810</td>\n",
       "      <td>0.289396</td>\n",
       "      <td>0.402513</td>\n",
       "      <td>0.526640</td>\n",
       "      <td>0.404092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251512</td>\n",
       "      <td>0.433129</td>\n",
       "      <td>0.400759</td>\n",
       "      <td>0.391974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442014</td>\n",
       "      <td>0.437673</td>\n",
       "      <td>0.492225</td>\n",
       "      <td>0.389495</td>\n",
       "      <td>0.507826</td>\n",
       "      <td>0.490856</td>\n",
       "      <td>0.373436</td>\n",
       "      <td>0.437228</td>\n",
       "      <td>0.491103</td>\n",
       "      <td>0.340949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.322319</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.436833</td>\n",
       "      <td>0.310591</td>\n",
       "      <td>0.251512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307938</td>\n",
       "      <td>0.282247</td>\n",
       "      <td>0.295941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436145</td>\n",
       "      <td>0.399608</td>\n",
       "      <td>0.378503</td>\n",
       "      <td>0.294022</td>\n",
       "      <td>0.397334</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.399324</td>\n",
       "      <td>0.262623</td>\n",
       "      <td>0.418334</td>\n",
       "      <td>0.316930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which</th>\n",
       "      <td>0.260210</td>\n",
       "      <td>0.455112</td>\n",
       "      <td>0.415099</td>\n",
       "      <td>0.352533</td>\n",
       "      <td>0.381433</td>\n",
       "      <td>0.433129</td>\n",
       "      <td>0.307938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387187</td>\n",
       "      <td>0.359945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494234</td>\n",
       "      <td>0.403046</td>\n",
       "      <td>0.293318</td>\n",
       "      <td>0.359397</td>\n",
       "      <td>0.372175</td>\n",
       "      <td>0.429679</td>\n",
       "      <td>0.346755</td>\n",
       "      <td>0.217538</td>\n",
       "      <td>0.456953</td>\n",
       "      <td>0.264499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whom</th>\n",
       "      <td>0.343792</td>\n",
       "      <td>0.410958</td>\n",
       "      <td>0.386007</td>\n",
       "      <td>0.510801</td>\n",
       "      <td>0.454696</td>\n",
       "      <td>0.400759</td>\n",
       "      <td>0.282247</td>\n",
       "      <td>0.387187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472407</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.471550</td>\n",
       "      <td>0.404236</td>\n",
       "      <td>0.532491</td>\n",
       "      <td>0.463114</td>\n",
       "      <td>0.425777</td>\n",
       "      <td>0.330136</td>\n",
       "      <td>0.444332</td>\n",
       "      <td>0.436777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>0.259073</td>\n",
       "      <td>0.314226</td>\n",
       "      <td>0.401284</td>\n",
       "      <td>0.305893</td>\n",
       "      <td>0.369421</td>\n",
       "      <td>0.391974</td>\n",
       "      <td>0.295941</td>\n",
       "      <td>0.359945</td>\n",
       "      <td>0.362601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400821</td>\n",
       "      <td>0.340487</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0.354442</td>\n",
       "      <td>0.355809</td>\n",
       "      <td>0.341493</td>\n",
       "      <td>0.359588</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>0.397146</td>\n",
       "      <td>0.334882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_PERSON</th>\n",
       "      <td>0.357365</td>\n",
       "      <td>0.421095</td>\n",
       "      <td>0.542812</td>\n",
       "      <td>0.414850</td>\n",
       "      <td>0.376861</td>\n",
       "      <td>0.377921</td>\n",
       "      <td>0.235903</td>\n",
       "      <td>0.320693</td>\n",
       "      <td>0.437336</td>\n",
       "      <td>0.348027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443467</td>\n",
       "      <td>0.487913</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>0.328502</td>\n",
       "      <td>0.398993</td>\n",
       "      <td>0.398445</td>\n",
       "      <td>0.412046</td>\n",
       "      <td>0.297201</td>\n",
       "      <td>0.436955</td>\n",
       "      <td>0.339357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_NORP</th>\n",
       "      <td>0.366928</td>\n",
       "      <td>0.364864</td>\n",
       "      <td>0.491109</td>\n",
       "      <td>0.477429</td>\n",
       "      <td>0.444286</td>\n",
       "      <td>0.290929</td>\n",
       "      <td>0.302175</td>\n",
       "      <td>0.495062</td>\n",
       "      <td>0.363916</td>\n",
       "      <td>0.333668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335204</td>\n",
       "      <td>0.499875</td>\n",
       "      <td>0.500123</td>\n",
       "      <td>0.353340</td>\n",
       "      <td>0.550485</td>\n",
       "      <td>0.508134</td>\n",
       "      <td>0.430329</td>\n",
       "      <td>0.484880</td>\n",
       "      <td>0.513720</td>\n",
       "      <td>0.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_FAC</th>\n",
       "      <td>0.301184</td>\n",
       "      <td>0.390455</td>\n",
       "      <td>0.354551</td>\n",
       "      <td>0.477777</td>\n",
       "      <td>0.516677</td>\n",
       "      <td>0.424087</td>\n",
       "      <td>0.500089</td>\n",
       "      <td>0.492394</td>\n",
       "      <td>0.523356</td>\n",
       "      <td>0.402916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331525</td>\n",
       "      <td>0.456313</td>\n",
       "      <td>0.579689</td>\n",
       "      <td>0.484461</td>\n",
       "      <td>0.552336</td>\n",
       "      <td>0.507709</td>\n",
       "      <td>0.376353</td>\n",
       "      <td>0.572469</td>\n",
       "      <td>0.472726</td>\n",
       "      <td>0.402081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_LOC</th>\n",
       "      <td>0.359273</td>\n",
       "      <td>0.524942</td>\n",
       "      <td>0.517463</td>\n",
       "      <td>0.491176</td>\n",
       "      <td>0.245997</td>\n",
       "      <td>0.371277</td>\n",
       "      <td>0.292299</td>\n",
       "      <td>0.355918</td>\n",
       "      <td>0.454157</td>\n",
       "      <td>0.386152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395856</td>\n",
       "      <td>0.482222</td>\n",
       "      <td>0.391255</td>\n",
       "      <td>0.290876</td>\n",
       "      <td>0.429143</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>0.379934</td>\n",
       "      <td>0.314733</td>\n",
       "      <td>0.501995</td>\n",
       "      <td>0.290118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_PRODUCT</th>\n",
       "      <td>0.379797</td>\n",
       "      <td>0.362328</td>\n",
       "      <td>0.353856</td>\n",
       "      <td>0.531186</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0.404791</td>\n",
       "      <td>0.314296</td>\n",
       "      <td>0.463993</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>0.272532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390762</td>\n",
       "      <td>0.522671</td>\n",
       "      <td>0.555862</td>\n",
       "      <td>0.401394</td>\n",
       "      <td>0.511744</td>\n",
       "      <td>0.487789</td>\n",
       "      <td>0.396433</td>\n",
       "      <td>0.395698</td>\n",
       "      <td>0.369882</td>\n",
       "      <td>0.435408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_EVENT</th>\n",
       "      <td>0.347802</td>\n",
       "      <td>0.355134</td>\n",
       "      <td>0.461028</td>\n",
       "      <td>0.381251</td>\n",
       "      <td>0.542415</td>\n",
       "      <td>0.510247</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.365643</td>\n",
       "      <td>0.417335</td>\n",
       "      <td>0.299050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485072</td>\n",
       "      <td>0.498405</td>\n",
       "      <td>0.381283</td>\n",
       "      <td>0.494985</td>\n",
       "      <td>0.461185</td>\n",
       "      <td>0.303225</td>\n",
       "      <td>0.460767</td>\n",
       "      <td>0.420041</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.418643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_WORK_OF_ART</th>\n",
       "      <td>0.263257</td>\n",
       "      <td>0.320428</td>\n",
       "      <td>0.350826</td>\n",
       "      <td>0.427797</td>\n",
       "      <td>0.322150</td>\n",
       "      <td>0.309277</td>\n",
       "      <td>0.257210</td>\n",
       "      <td>0.336015</td>\n",
       "      <td>0.356753</td>\n",
       "      <td>0.241738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372842</td>\n",
       "      <td>0.454975</td>\n",
       "      <td>0.366585</td>\n",
       "      <td>0.334352</td>\n",
       "      <td>0.375585</td>\n",
       "      <td>0.336267</td>\n",
       "      <td>0.252081</td>\n",
       "      <td>0.311469</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.238342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_LANGUAGE</th>\n",
       "      <td>0.428141</td>\n",
       "      <td>0.499188</td>\n",
       "      <td>0.481524</td>\n",
       "      <td>0.537392</td>\n",
       "      <td>0.507089</td>\n",
       "      <td>0.365169</td>\n",
       "      <td>0.318686</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.357677</td>\n",
       "      <td>0.462819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597839</td>\n",
       "      <td>0.562821</td>\n",
       "      <td>0.377318</td>\n",
       "      <td>0.482948</td>\n",
       "      <td>0.558430</td>\n",
       "      <td>0.514759</td>\n",
       "      <td>0.430473</td>\n",
       "      <td>0.359404</td>\n",
       "      <td>0.616305</td>\n",
       "      <td>0.371478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_DATE</th>\n",
       "      <td>0.378417</td>\n",
       "      <td>0.341378</td>\n",
       "      <td>0.376537</td>\n",
       "      <td>0.544185</td>\n",
       "      <td>0.373898</td>\n",
       "      <td>0.392154</td>\n",
       "      <td>0.317716</td>\n",
       "      <td>0.380892</td>\n",
       "      <td>0.406829</td>\n",
       "      <td>0.407738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494893</td>\n",
       "      <td>0.499179</td>\n",
       "      <td>0.492738</td>\n",
       "      <td>0.412091</td>\n",
       "      <td>0.418461</td>\n",
       "      <td>0.426559</td>\n",
       "      <td>0.388036</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.233181</td>\n",
       "      <td>0.357334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_TIME</th>\n",
       "      <td>0.538566</td>\n",
       "      <td>0.591095</td>\n",
       "      <td>0.612909</td>\n",
       "      <td>0.547739</td>\n",
       "      <td>0.487773</td>\n",
       "      <td>0.512577</td>\n",
       "      <td>0.387109</td>\n",
       "      <td>0.373696</td>\n",
       "      <td>0.546095</td>\n",
       "      <td>0.466721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628628</td>\n",
       "      <td>0.525902</td>\n",
       "      <td>0.439273</td>\n",
       "      <td>0.533355</td>\n",
       "      <td>0.545392</td>\n",
       "      <td>0.611340</td>\n",
       "      <td>0.549828</td>\n",
       "      <td>0.415294</td>\n",
       "      <td>0.694196</td>\n",
       "      <td>0.418556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_PERCENT</th>\n",
       "      <td>0.362071</td>\n",
       "      <td>0.422771</td>\n",
       "      <td>0.384147</td>\n",
       "      <td>0.477941</td>\n",
       "      <td>0.323469</td>\n",
       "      <td>0.336978</td>\n",
       "      <td>0.324744</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.483002</td>\n",
       "      <td>0.399783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516611</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.430534</td>\n",
       "      <td>0.393184</td>\n",
       "      <td>0.395412</td>\n",
       "      <td>0.506825</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>0.313597</td>\n",
       "      <td>0.464963</td>\n",
       "      <td>0.221774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_MONEY</th>\n",
       "      <td>0.482786</td>\n",
       "      <td>0.629843</td>\n",
       "      <td>0.670120</td>\n",
       "      <td>0.510028</td>\n",
       "      <td>0.565775</td>\n",
       "      <td>0.583598</td>\n",
       "      <td>0.546831</td>\n",
       "      <td>0.489159</td>\n",
       "      <td>0.704364</td>\n",
       "      <td>0.497091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527686</td>\n",
       "      <td>0.610130</td>\n",
       "      <td>0.371896</td>\n",
       "      <td>0.564319</td>\n",
       "      <td>0.535404</td>\n",
       "      <td>0.502125</td>\n",
       "      <td>0.511558</td>\n",
       "      <td>0.559665</td>\n",
       "      <td>0.631989</td>\n",
       "      <td>0.395878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_ORDINAL</th>\n",
       "      <td>0.281588</td>\n",
       "      <td>0.350702</td>\n",
       "      <td>0.425469</td>\n",
       "      <td>0.431920</td>\n",
       "      <td>0.330723</td>\n",
       "      <td>0.353904</td>\n",
       "      <td>0.353835</td>\n",
       "      <td>0.429190</td>\n",
       "      <td>0.471041</td>\n",
       "      <td>0.337874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317429</td>\n",
       "      <td>0.350378</td>\n",
       "      <td>0.524440</td>\n",
       "      <td>0.316079</td>\n",
       "      <td>0.410738</td>\n",
       "      <td>0.476561</td>\n",
       "      <td>0.393728</td>\n",
       "      <td>0.448217</td>\n",
       "      <td>0.373676</td>\n",
       "      <td>0.364629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_CARDINAL</th>\n",
       "      <td>0.271750</td>\n",
       "      <td>0.396635</td>\n",
       "      <td>0.535677</td>\n",
       "      <td>0.283367</td>\n",
       "      <td>0.424587</td>\n",
       "      <td>0.398126</td>\n",
       "      <td>0.385373</td>\n",
       "      <td>0.391382</td>\n",
       "      <td>0.505177</td>\n",
       "      <td>0.357892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588194</td>\n",
       "      <td>0.349643</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.340057</td>\n",
       "      <td>0.244549</td>\n",
       "      <td>0.285790</td>\n",
       "      <td>0.388541</td>\n",
       "      <td>0.448806</td>\n",
       "      <td>0.415612</td>\n",
       "      <td>0.374779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_GPE</th>\n",
       "      <td>0.280192</td>\n",
       "      <td>0.457257</td>\n",
       "      <td>0.432685</td>\n",
       "      <td>0.412357</td>\n",
       "      <td>0.501687</td>\n",
       "      <td>0.484466</td>\n",
       "      <td>0.370959</td>\n",
       "      <td>0.231996</td>\n",
       "      <td>0.383996</td>\n",
       "      <td>0.399469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451705</td>\n",
       "      <td>0.545882</td>\n",
       "      <td>0.267729</td>\n",
       "      <td>0.440728</td>\n",
       "      <td>0.475141</td>\n",
       "      <td>0.372403</td>\n",
       "      <td>0.384075</td>\n",
       "      <td>0.298753</td>\n",
       "      <td>0.423991</td>\n",
       "      <td>0.335970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_ORG</th>\n",
       "      <td>0.240002</td>\n",
       "      <td>0.363969</td>\n",
       "      <td>0.433271</td>\n",
       "      <td>0.377260</td>\n",
       "      <td>0.327515</td>\n",
       "      <td>0.339879</td>\n",
       "      <td>0.291912</td>\n",
       "      <td>0.333805</td>\n",
       "      <td>0.436902</td>\n",
       "      <td>0.281724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296911</td>\n",
       "      <td>0.432969</td>\n",
       "      <td>0.338982</td>\n",
       "      <td>0.288066</td>\n",
       "      <td>0.374763</td>\n",
       "      <td>0.375843</td>\n",
       "      <td>0.295143</td>\n",
       "      <td>0.346126</td>\n",
       "      <td>0.344234</td>\n",
       "      <td>0.267685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_PERSON</th>\n",
       "      <td>0.276217</td>\n",
       "      <td>0.343093</td>\n",
       "      <td>0.382468</td>\n",
       "      <td>0.411398</td>\n",
       "      <td>0.311519</td>\n",
       "      <td>0.305828</td>\n",
       "      <td>0.148714</td>\n",
       "      <td>0.230314</td>\n",
       "      <td>0.299427</td>\n",
       "      <td>0.285449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348139</td>\n",
       "      <td>0.417822</td>\n",
       "      <td>0.347186</td>\n",
       "      <td>0.289552</td>\n",
       "      <td>0.415309</td>\n",
       "      <td>0.436313</td>\n",
       "      <td>0.335526</td>\n",
       "      <td>0.216158</td>\n",
       "      <td>0.393832</td>\n",
       "      <td>0.279738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_NORP</th>\n",
       "      <td>0.279759</td>\n",
       "      <td>0.443307</td>\n",
       "      <td>0.437268</td>\n",
       "      <td>0.397277</td>\n",
       "      <td>0.335654</td>\n",
       "      <td>0.398110</td>\n",
       "      <td>0.265003</td>\n",
       "      <td>0.206981</td>\n",
       "      <td>0.378392</td>\n",
       "      <td>0.335237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545541</td>\n",
       "      <td>0.352630</td>\n",
       "      <td>0.333443</td>\n",
       "      <td>0.379190</td>\n",
       "      <td>0.305782</td>\n",
       "      <td>0.362023</td>\n",
       "      <td>0.410080</td>\n",
       "      <td>0.258181</td>\n",
       "      <td>0.456547</td>\n",
       "      <td>0.216986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_FAC</th>\n",
       "      <td>0.309061</td>\n",
       "      <td>0.312968</td>\n",
       "      <td>0.344018</td>\n",
       "      <td>0.489208</td>\n",
       "      <td>0.360131</td>\n",
       "      <td>0.375028</td>\n",
       "      <td>0.322842</td>\n",
       "      <td>0.381600</td>\n",
       "      <td>0.399833</td>\n",
       "      <td>0.344309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493809</td>\n",
       "      <td>0.392641</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.417279</td>\n",
       "      <td>0.357355</td>\n",
       "      <td>0.353342</td>\n",
       "      <td>0.400347</td>\n",
       "      <td>0.367893</td>\n",
       "      <td>0.274051</td>\n",
       "      <td>0.302120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_LOC</th>\n",
       "      <td>0.309011</td>\n",
       "      <td>0.396062</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.498431</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.312276</td>\n",
       "      <td>0.255370</td>\n",
       "      <td>0.298207</td>\n",
       "      <td>0.306105</td>\n",
       "      <td>0.415736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370501</td>\n",
       "      <td>0.547437</td>\n",
       "      <td>0.354297</td>\n",
       "      <td>0.361763</td>\n",
       "      <td>0.522449</td>\n",
       "      <td>0.467356</td>\n",
       "      <td>0.342950</td>\n",
       "      <td>0.275088</td>\n",
       "      <td>0.429151</td>\n",
       "      <td>0.332587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_PRODUCT</th>\n",
       "      <td>0.417828</td>\n",
       "      <td>0.399831</td>\n",
       "      <td>0.442259</td>\n",
       "      <td>0.411998</td>\n",
       "      <td>0.487434</td>\n",
       "      <td>0.494751</td>\n",
       "      <td>0.450720</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>0.578684</td>\n",
       "      <td>0.397998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564664</td>\n",
       "      <td>0.381563</td>\n",
       "      <td>0.491900</td>\n",
       "      <td>0.497761</td>\n",
       "      <td>0.432242</td>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.400712</td>\n",
       "      <td>0.448527</td>\n",
       "      <td>0.482121</td>\n",
       "      <td>0.388644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_EVENT</th>\n",
       "      <td>0.332169</td>\n",
       "      <td>0.434246</td>\n",
       "      <td>0.545355</td>\n",
       "      <td>0.344341</td>\n",
       "      <td>0.489054</td>\n",
       "      <td>0.446098</td>\n",
       "      <td>0.323898</td>\n",
       "      <td>0.379547</td>\n",
       "      <td>0.391125</td>\n",
       "      <td>0.265679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517942</td>\n",
       "      <td>0.504062</td>\n",
       "      <td>0.251905</td>\n",
       "      <td>0.422988</td>\n",
       "      <td>0.415006</td>\n",
       "      <td>0.260352</td>\n",
       "      <td>0.438798</td>\n",
       "      <td>0.406229</td>\n",
       "      <td>0.493832</td>\n",
       "      <td>0.380307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_WORK_OF_ART</th>\n",
       "      <td>0.391371</td>\n",
       "      <td>0.445512</td>\n",
       "      <td>0.412578</td>\n",
       "      <td>0.562173</td>\n",
       "      <td>0.472915</td>\n",
       "      <td>0.442014</td>\n",
       "      <td>0.436145</td>\n",
       "      <td>0.494234</td>\n",
       "      <td>0.472407</td>\n",
       "      <td>0.400821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575626</td>\n",
       "      <td>0.560893</td>\n",
       "      <td>0.456752</td>\n",
       "      <td>0.621349</td>\n",
       "      <td>0.588004</td>\n",
       "      <td>0.412776</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.477852</td>\n",
       "      <td>0.432029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_LANGUAGE</th>\n",
       "      <td>0.374754</td>\n",
       "      <td>0.387252</td>\n",
       "      <td>0.507149</td>\n",
       "      <td>0.351014</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.437673</td>\n",
       "      <td>0.399608</td>\n",
       "      <td>0.403046</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.340487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544783</td>\n",
       "      <td>0.432732</td>\n",
       "      <td>0.342970</td>\n",
       "      <td>0.484958</td>\n",
       "      <td>0.500798</td>\n",
       "      <td>0.505538</td>\n",
       "      <td>0.536635</td>\n",
       "      <td>0.403669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_DATE</th>\n",
       "      <td>0.328225</td>\n",
       "      <td>0.544785</td>\n",
       "      <td>0.595443</td>\n",
       "      <td>0.359026</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.492225</td>\n",
       "      <td>0.378503</td>\n",
       "      <td>0.293318</td>\n",
       "      <td>0.471550</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560893</td>\n",
       "      <td>0.544783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416070</td>\n",
       "      <td>0.413982</td>\n",
       "      <td>0.335578</td>\n",
       "      <td>0.438426</td>\n",
       "      <td>0.352550</td>\n",
       "      <td>0.534817</td>\n",
       "      <td>0.352767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_TIME</th>\n",
       "      <td>0.297465</td>\n",
       "      <td>0.459130</td>\n",
       "      <td>0.521874</td>\n",
       "      <td>0.375087</td>\n",
       "      <td>0.231219</td>\n",
       "      <td>0.389495</td>\n",
       "      <td>0.294022</td>\n",
       "      <td>0.359397</td>\n",
       "      <td>0.404236</td>\n",
       "      <td>0.354442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456752</td>\n",
       "      <td>0.432732</td>\n",
       "      <td>0.416070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316073</td>\n",
       "      <td>0.479850</td>\n",
       "      <td>0.337852</td>\n",
       "      <td>0.297356</td>\n",
       "      <td>0.364770</td>\n",
       "      <td>0.406097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_PERCENT</th>\n",
       "      <td>0.336358</td>\n",
       "      <td>0.497970</td>\n",
       "      <td>0.580396</td>\n",
       "      <td>0.320718</td>\n",
       "      <td>0.316996</td>\n",
       "      <td>0.507826</td>\n",
       "      <td>0.397334</td>\n",
       "      <td>0.372175</td>\n",
       "      <td>0.532491</td>\n",
       "      <td>0.355809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621349</td>\n",
       "      <td>0.342970</td>\n",
       "      <td>0.413982</td>\n",
       "      <td>0.316073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363160</td>\n",
       "      <td>0.439395</td>\n",
       "      <td>0.382115</td>\n",
       "      <td>0.390081</td>\n",
       "      <td>0.385607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_MONEY</th>\n",
       "      <td>0.310173</td>\n",
       "      <td>0.425309</td>\n",
       "      <td>0.543716</td>\n",
       "      <td>0.363193</td>\n",
       "      <td>0.532049</td>\n",
       "      <td>0.490856</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.429679</td>\n",
       "      <td>0.463114</td>\n",
       "      <td>0.341493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588004</td>\n",
       "      <td>0.484958</td>\n",
       "      <td>0.335578</td>\n",
       "      <td>0.479850</td>\n",
       "      <td>0.363160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.478606</td>\n",
       "      <td>0.471472</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.390268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_ORDINAL</th>\n",
       "      <td>0.274145</td>\n",
       "      <td>0.426977</td>\n",
       "      <td>0.324952</td>\n",
       "      <td>0.440069</td>\n",
       "      <td>0.367383</td>\n",
       "      <td>0.373436</td>\n",
       "      <td>0.399324</td>\n",
       "      <td>0.346755</td>\n",
       "      <td>0.425777</td>\n",
       "      <td>0.359588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412776</td>\n",
       "      <td>0.500798</td>\n",
       "      <td>0.438426</td>\n",
       "      <td>0.337852</td>\n",
       "      <td>0.439395</td>\n",
       "      <td>0.478606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365910</td>\n",
       "      <td>0.370573</td>\n",
       "      <td>0.307948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_CARDINAL</th>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.493475</td>\n",
       "      <td>0.454619</td>\n",
       "      <td>0.468581</td>\n",
       "      <td>0.294792</td>\n",
       "      <td>0.437228</td>\n",
       "      <td>0.262623</td>\n",
       "      <td>0.217538</td>\n",
       "      <td>0.330136</td>\n",
       "      <td>0.400024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500027</td>\n",
       "      <td>0.505538</td>\n",
       "      <td>0.352550</td>\n",
       "      <td>0.297356</td>\n",
       "      <td>0.382115</td>\n",
       "      <td>0.471472</td>\n",
       "      <td>0.365910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381303</td>\n",
       "      <td>0.329311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_GPE</th>\n",
       "      <td>0.357638</td>\n",
       "      <td>0.411387</td>\n",
       "      <td>0.434054</td>\n",
       "      <td>0.506385</td>\n",
       "      <td>0.375615</td>\n",
       "      <td>0.491103</td>\n",
       "      <td>0.418334</td>\n",
       "      <td>0.456953</td>\n",
       "      <td>0.444332</td>\n",
       "      <td>0.397146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477852</td>\n",
       "      <td>0.536635</td>\n",
       "      <td>0.534817</td>\n",
       "      <td>0.364770</td>\n",
       "      <td>0.390081</td>\n",
       "      <td>0.429167</td>\n",
       "      <td>0.370573</td>\n",
       "      <td>0.381303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_ORG</th>\n",
       "      <td>0.261070</td>\n",
       "      <td>0.421921</td>\n",
       "      <td>0.357629</td>\n",
       "      <td>0.445194</td>\n",
       "      <td>0.342236</td>\n",
       "      <td>0.340949</td>\n",
       "      <td>0.316930</td>\n",
       "      <td>0.264499</td>\n",
       "      <td>0.436777</td>\n",
       "      <td>0.334882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432029</td>\n",
       "      <td>0.403669</td>\n",
       "      <td>0.352767</td>\n",
       "      <td>0.406097</td>\n",
       "      <td>0.385607</td>\n",
       "      <td>0.390268</td>\n",
       "      <td>0.307948</td>\n",
       "      <td>0.329311</td>\n",
       "      <td>0.444683</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    why       how     whose      what      when     where  \\\n",
       "why            0.000000  0.369390  0.363307  0.283515  0.368420  0.370810   \n",
       "how            0.369390  0.000000  0.360829  0.465410  0.489510  0.289396   \n",
       "whose          0.363307  0.360829  0.000000  0.573273  0.484266  0.402513   \n",
       "what           0.283515  0.465410  0.573273  0.000000  0.490411  0.526640   \n",
       "when           0.368420  0.489510  0.484266  0.490411  0.000000  0.404092   \n",
       "where          0.370810  0.289396  0.402513  0.526640  0.404092  0.000000   \n",
       "who            0.317100  0.322319  0.434900  0.436833  0.310591  0.251512   \n",
       "which          0.260210  0.455112  0.415099  0.352533  0.381433  0.433129   \n",
       "whom           0.343792  0.410958  0.386007  0.510801  0.454696  0.400759   \n",
       "others         0.259073  0.314226  0.401284  0.305893  0.369421  0.391974   \n",
       "q_PERSON       0.357365  0.421095  0.542812  0.414850  0.376861  0.377921   \n",
       "q_NORP         0.366928  0.364864  0.491109  0.477429  0.444286  0.290929   \n",
       "q_FAC          0.301184  0.390455  0.354551  0.477777  0.516677  0.424087   \n",
       "q_LOC          0.359273  0.524942  0.517463  0.491176  0.245997  0.371277   \n",
       "q_PRODUCT      0.379797  0.362328  0.353856  0.531186  0.386609  0.404791   \n",
       "q_EVENT        0.347802  0.355134  0.461028  0.381251  0.542415  0.510247   \n",
       "q_WORK_OF_ART  0.263257  0.320428  0.350826  0.427797  0.322150  0.309277   \n",
       "q_LANGUAGE     0.428141  0.499188  0.481524  0.537392  0.507089  0.365169   \n",
       "q_DATE         0.378417  0.341378  0.376537  0.544185  0.373898  0.392154   \n",
       "q_TIME         0.538566  0.591095  0.612909  0.547739  0.487773  0.512577   \n",
       "q_PERCENT      0.362071  0.422771  0.384147  0.477941  0.323469  0.336978   \n",
       "q_MONEY        0.482786  0.629843  0.670120  0.510028  0.565775  0.583598   \n",
       "q_ORDINAL      0.281588  0.350702  0.425469  0.431920  0.330723  0.353904   \n",
       "q_CARDINAL     0.271750  0.396635  0.535677  0.283367  0.424587  0.398126   \n",
       "q_GPE          0.280192  0.457257  0.432685  0.412357  0.501687  0.484466   \n",
       "q_ORG          0.240002  0.363969  0.433271  0.377260  0.327515  0.339879   \n",
       "a_PERSON       0.276217  0.343093  0.382468  0.411398  0.311519  0.305828   \n",
       "a_NORP         0.279759  0.443307  0.437268  0.397277  0.335654  0.398110   \n",
       "a_FAC          0.309061  0.312968  0.344018  0.489208  0.360131  0.375028   \n",
       "a_LOC          0.309011  0.396062  0.394309  0.498431  0.427451  0.312276   \n",
       "a_PRODUCT      0.417828  0.399831  0.442259  0.411998  0.487434  0.494751   \n",
       "a_EVENT        0.332169  0.434246  0.545355  0.344341  0.489054  0.446098   \n",
       "a_WORK_OF_ART  0.391371  0.445512  0.412578  0.562173  0.472915  0.442014   \n",
       "a_LANGUAGE     0.374754  0.387252  0.507149  0.351014  0.414894  0.437673   \n",
       "a_DATE         0.328225  0.544785  0.595443  0.359026  0.499270  0.492225   \n",
       "a_TIME         0.297465  0.459130  0.521874  0.375087  0.231219  0.389495   \n",
       "a_PERCENT      0.336358  0.497970  0.580396  0.320718  0.316996  0.507826   \n",
       "a_MONEY        0.310173  0.425309  0.543716  0.363193  0.532049  0.490856   \n",
       "a_ORDINAL      0.274145  0.426977  0.324952  0.440069  0.367383  0.373436   \n",
       "a_CARDINAL     0.332458  0.493475  0.454619  0.468581  0.294792  0.437228   \n",
       "a_GPE          0.357638  0.411387  0.434054  0.506385  0.375615  0.491103   \n",
       "a_ORG          0.261070  0.421921  0.357629  0.445194  0.342236  0.340949   \n",
       "\n",
       "                    who     which      whom    others    ...     \\\n",
       "why            0.317100  0.260210  0.343792  0.259073    ...      \n",
       "how            0.322319  0.455112  0.410958  0.314226    ...      \n",
       "whose          0.434900  0.415099  0.386007  0.401284    ...      \n",
       "what           0.436833  0.352533  0.510801  0.305893    ...      \n",
       "when           0.310591  0.381433  0.454696  0.369421    ...      \n",
       "where          0.251512  0.433129  0.400759  0.391974    ...      \n",
       "who            0.000000  0.307938  0.282247  0.295941    ...      \n",
       "which          0.307938  0.000000  0.387187  0.359945    ...      \n",
       "whom           0.282247  0.387187  0.000000  0.362601    ...      \n",
       "others         0.295941  0.359945  0.362601  0.000000    ...      \n",
       "q_PERSON       0.235903  0.320693  0.437336  0.348027    ...      \n",
       "q_NORP         0.302175  0.495062  0.363916  0.333668    ...      \n",
       "q_FAC          0.500089  0.492394  0.523356  0.402916    ...      \n",
       "q_LOC          0.292299  0.355918  0.454157  0.386152    ...      \n",
       "q_PRODUCT      0.314296  0.463993  0.247899  0.272532    ...      \n",
       "q_EVENT        0.384375  0.365643  0.417335  0.299050    ...      \n",
       "q_WORK_OF_ART  0.257210  0.336015  0.356753  0.241738    ...      \n",
       "q_LANGUAGE     0.318686  0.336469  0.357677  0.462819    ...      \n",
       "q_DATE         0.317716  0.380892  0.406829  0.407738    ...      \n",
       "q_TIME         0.387109  0.373696  0.546095  0.466721    ...      \n",
       "q_PERCENT      0.324744  0.260841  0.483002  0.399783    ...      \n",
       "q_MONEY        0.546831  0.489159  0.704364  0.497091    ...      \n",
       "q_ORDINAL      0.353835  0.429190  0.471041  0.337874    ...      \n",
       "q_CARDINAL     0.385373  0.391382  0.505177  0.357892    ...      \n",
       "q_GPE          0.370959  0.231996  0.383996  0.399469    ...      \n",
       "q_ORG          0.291912  0.333805  0.436902  0.281724    ...      \n",
       "a_PERSON       0.148714  0.230314  0.299427  0.285449    ...      \n",
       "a_NORP         0.265003  0.206981  0.378392  0.335237    ...      \n",
       "a_FAC          0.322842  0.381600  0.399833  0.344309    ...      \n",
       "a_LOC          0.255370  0.298207  0.306105  0.415736    ...      \n",
       "a_PRODUCT      0.450720  0.328322  0.578684  0.397998    ...      \n",
       "a_EVENT        0.323898  0.379547  0.391125  0.265679    ...      \n",
       "a_WORK_OF_ART  0.436145  0.494234  0.472407  0.400821    ...      \n",
       "a_LANGUAGE     0.399608  0.403046  0.550300  0.340487    ...      \n",
       "a_DATE         0.378503  0.293318  0.471550  0.417669    ...      \n",
       "a_TIME         0.294022  0.359397  0.404236  0.354442    ...      \n",
       "a_PERCENT      0.397334  0.372175  0.532491  0.355809    ...      \n",
       "a_MONEY        0.413007  0.429679  0.463114  0.341493    ...      \n",
       "a_ORDINAL      0.399324  0.346755  0.425777  0.359588    ...      \n",
       "a_CARDINAL     0.262623  0.217538  0.330136  0.400024    ...      \n",
       "a_GPE          0.418334  0.456953  0.444332  0.397146    ...      \n",
       "a_ORG          0.316930  0.264499  0.436777  0.334882    ...      \n",
       "\n",
       "               a_WORK_OF_ART  a_LANGUAGE    a_DATE    a_TIME  a_PERCENT  \\\n",
       "why                 0.391371    0.374754  0.328225  0.297465   0.336358   \n",
       "how                 0.445512    0.387252  0.544785  0.459130   0.497970   \n",
       "whose               0.412578    0.507149  0.595443  0.521874   0.580396   \n",
       "what                0.562173    0.351014  0.359026  0.375087   0.320718   \n",
       "when                0.472915    0.414894  0.499270  0.231219   0.316996   \n",
       "where               0.442014    0.437673  0.492225  0.389495   0.507826   \n",
       "who                 0.436145    0.399608  0.378503  0.294022   0.397334   \n",
       "which               0.494234    0.403046  0.293318  0.359397   0.372175   \n",
       "whom                0.472407    0.550300  0.471550  0.404236   0.532491   \n",
       "others              0.400821    0.340487  0.417669  0.354442   0.355809   \n",
       "q_PERSON            0.443467    0.487913  0.266957  0.328502   0.398993   \n",
       "q_NORP              0.335204    0.499875  0.500123  0.353340   0.550485   \n",
       "q_FAC               0.331525    0.456313  0.579689  0.484461   0.552336   \n",
       "q_LOC               0.395856    0.482222  0.391255  0.290876   0.429143   \n",
       "q_PRODUCT           0.390762    0.522671  0.555862  0.401394   0.511744   \n",
       "q_EVENT             0.485072    0.498405  0.381283  0.494985   0.461185   \n",
       "q_WORK_OF_ART       0.372842    0.454975  0.366585  0.334352   0.375585   \n",
       "q_LANGUAGE          0.597839    0.562821  0.377318  0.482948   0.558430   \n",
       "q_DATE              0.494893    0.499179  0.492738  0.412091   0.418461   \n",
       "q_TIME              0.628628    0.525902  0.439273  0.533355   0.545392   \n",
       "q_PERCENT           0.516611    0.391275  0.430534  0.393184   0.395412   \n",
       "q_MONEY             0.527686    0.610130  0.371896  0.564319   0.535404   \n",
       "q_ORDINAL           0.317429    0.350378  0.524440  0.316079   0.410738   \n",
       "q_CARDINAL          0.588194    0.349643  0.377953  0.340057   0.244549   \n",
       "q_GPE               0.451705    0.545882  0.267729  0.440728   0.475141   \n",
       "q_ORG               0.296911    0.432969  0.338982  0.288066   0.374763   \n",
       "a_PERSON            0.348139    0.417822  0.347186  0.289552   0.415309   \n",
       "a_NORP              0.545541    0.352630  0.333443  0.379190   0.305782   \n",
       "a_FAC               0.493809    0.392641  0.497665  0.417279   0.357355   \n",
       "a_LOC               0.370501    0.547437  0.354297  0.361763   0.522449   \n",
       "a_PRODUCT           0.564664    0.381563  0.491900  0.497761   0.432242   \n",
       "a_EVENT             0.517942    0.504062  0.251905  0.422988   0.415006   \n",
       "a_WORK_OF_ART       0.000000    0.575626  0.560893  0.456752   0.621349   \n",
       "a_LANGUAGE          0.575626    0.000000  0.544783  0.432732   0.342970   \n",
       "a_DATE              0.560893    0.544783  0.000000  0.416070   0.413982   \n",
       "a_TIME              0.456752    0.432732  0.416070  0.000000   0.316073   \n",
       "a_PERCENT           0.621349    0.342970  0.413982  0.316073   0.000000   \n",
       "a_MONEY             0.588004    0.484958  0.335578  0.479850   0.363160   \n",
       "a_ORDINAL           0.412776    0.500798  0.438426  0.337852   0.439395   \n",
       "a_CARDINAL          0.500027    0.505538  0.352550  0.297356   0.382115   \n",
       "a_GPE               0.477852    0.536635  0.534817  0.364770   0.390081   \n",
       "a_ORG               0.432029    0.403669  0.352767  0.406097   0.385607   \n",
       "\n",
       "                a_MONEY  a_ORDINAL  a_CARDINAL     a_GPE     a_ORG  \n",
       "why            0.310173   0.274145    0.332458  0.357638  0.261070  \n",
       "how            0.425309   0.426977    0.493475  0.411387  0.421921  \n",
       "whose          0.543716   0.324952    0.454619  0.434054  0.357629  \n",
       "what           0.363193   0.440069    0.468581  0.506385  0.445194  \n",
       "when           0.532049   0.367383    0.294792  0.375615  0.342236  \n",
       "where          0.490856   0.373436    0.437228  0.491103  0.340949  \n",
       "who            0.413007   0.399324    0.262623  0.418334  0.316930  \n",
       "which          0.429679   0.346755    0.217538  0.456953  0.264499  \n",
       "whom           0.463114   0.425777    0.330136  0.444332  0.436777  \n",
       "others         0.341493   0.359588    0.400024  0.397146  0.334882  \n",
       "q_PERSON       0.398445   0.412046    0.297201  0.436955  0.339357  \n",
       "q_NORP         0.508134   0.430329    0.484880  0.513720  0.457400  \n",
       "q_FAC          0.507709   0.376353    0.572469  0.472726  0.402081  \n",
       "q_LOC          0.529939   0.379934    0.314733  0.501995  0.290118  \n",
       "q_PRODUCT      0.487789   0.396433    0.395698  0.369882  0.435408  \n",
       "q_EVENT        0.303225   0.460767    0.420041  0.404625  0.418643  \n",
       "q_WORK_OF_ART  0.336267   0.252081    0.311469  0.300147  0.238342  \n",
       "q_LANGUAGE     0.514759   0.430473    0.359404  0.616305  0.371478  \n",
       "q_DATE         0.426559   0.388036    0.311400  0.233181  0.357334  \n",
       "q_TIME         0.611340   0.549828    0.415294  0.694196  0.418556  \n",
       "q_PERCENT      0.506825   0.302478    0.313597  0.464963  0.221774  \n",
       "q_MONEY        0.502125   0.511558    0.559665  0.631989  0.395878  \n",
       "q_ORDINAL      0.476561   0.393728    0.448217  0.373676  0.364629  \n",
       "q_CARDINAL     0.285790   0.388541    0.448806  0.415612  0.374779  \n",
       "q_GPE          0.372403   0.384075    0.298753  0.423991  0.335970  \n",
       "q_ORG          0.375843   0.295143    0.346126  0.344234  0.267685  \n",
       "a_PERSON       0.436313   0.335526    0.216158  0.393832  0.279738  \n",
       "a_NORP         0.362023   0.410080    0.258181  0.456547  0.216986  \n",
       "a_FAC          0.353342   0.400347    0.367893  0.274051  0.302120  \n",
       "a_LOC          0.467356   0.342950    0.275088  0.429151  0.332587  \n",
       "a_PRODUCT      0.508909   0.400712    0.448527  0.482121  0.388644  \n",
       "a_EVENT        0.260352   0.438798    0.406229  0.493832  0.380307  \n",
       "a_WORK_OF_ART  0.588004   0.412776    0.500027  0.477852  0.432029  \n",
       "a_LANGUAGE     0.484958   0.500798    0.505538  0.536635  0.403669  \n",
       "a_DATE         0.335578   0.438426    0.352550  0.534817  0.352767  \n",
       "a_TIME         0.479850   0.337852    0.297356  0.364770  0.406097  \n",
       "a_PERCENT      0.363160   0.439395    0.382115  0.390081  0.385607  \n",
       "a_MONEY        0.000000   0.478606    0.471472  0.429167  0.390268  \n",
       "a_ORDINAL      0.478606   0.000000    0.365910  0.370573  0.307948  \n",
       "a_CARDINAL     0.471472   0.365910    0.000000  0.381303  0.329311  \n",
       "a_GPE          0.429167   0.370573    0.381303  0.000000  0.444683  \n",
       "a_ORG          0.390268   0.307948    0.329311  0.444683  0.000000  \n",
       "\n",
       "[42 rows x 42 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eucli_matrix_df = pd.DataFrame(question_answer_dis, index = row_column_list, columns= row_column_list)\n",
    "eucli_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_count(doc_ner_list):\n",
    "    count = Counter(doc_ner_list)\n",
    "    map_count = []\n",
    "    for i in count.items():\n",
    "        map_count.append(i)\n",
    "    return map_count\n",
    "\n",
    "def bag_of_words(doc_ner_list, unique_ner):\n",
    "    dis_matrix = np.zeros(len(unique_ner), dtype = float)\n",
    "    nbow = word_count(doc_ner_list)\n",
    "   \n",
    "    doc_len = len(doc_ner_list)\n",
    "    for i, freq in nbow:\n",
    "        dis_matrix[unique_ner.index(i)] = freq / float(doc_len)  # Normalized word frequencies.\n",
    "    return dis_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ner_combination(map_que_ner, map_ans_ner):\n",
    "     \n",
    "    unique_removed_new_ner = list(set(map_que_ner + map_ans_ner))\n",
    "    return unique_removed_new_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyemd import emd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qntypefun(qnlist):\n",
    "    punc=set(\",./;'?&-\")\n",
    "\n",
    "    common_list = []\n",
    "    for i in qnlist:\n",
    "        list1 = (i.lower().split())\n",
    "        list2 = list(set(list1).intersection(qtntype_list)) \n",
    "        for j in list2:\n",
    "            strp =''.join(c for c in j if not c in punc)\n",
    "            common_list.append(strp) \n",
    "        if list2 == []:\n",
    "            common_list.append('others')\n",
    "        \n",
    "        \n",
    "    return common_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tag distance ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sqd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tagdistance = [] \n",
    "\n",
    "for i in range(len(sqd_data)):\n",
    "    paragraph_pointer = sqd_data.data[i]['paragraphs'] \n",
    "\n",
    "    for k in range(len(paragraph_pointer)):#no of paragraphs in a row of the df\n",
    "\n",
    "        \n",
    "        processed_sen_list, process_sen_tokenized_list = preprocess_text(paragraph_pointer[k]['context']) \n",
    "        processed_que_list = preprocess_question(paragraph_pointer[k]['qas'])\n",
    "\n",
    "        \n",
    "\n",
    "        ls = [] \n",
    "\n",
    "        que_type_clean = qntypefun(processed_que_list)\n",
    "\n",
    "        for m in range(len(que_type_clean)):\n",
    "\n",
    "            map_que_ner = []\n",
    "            map_que_ner.append(que_type_clean[m])\n",
    "            #print(\"Que_NER\", \" \", map_que_ner)\n",
    "            for j in range(len(processed_sen_list)):\n",
    "\n",
    "\n",
    "\n",
    "                map_ans_ner = []\n",
    "                ans_ner = nlp(processed_sen_list[j])\n",
    "                for ent in ans_ner.ents:\n",
    "                    map_ans_ner.append('a_' + ent.label_)\n",
    "                #print(\"Ans_NER\", \" \", map_ans_ner)\n",
    "                unique_ner = ner_combination(map_que_ner, map_ans_ner)\n",
    "                #print(\"Unique_NER\", \" \", unique_ner)\n",
    "                #print()\n",
    "                # distance_matrix = np.zeros((len(unique_ner), len(unique_ner)))\n",
    "                d_1 = bag_of_words(map_que_ner, unique_ner)\n",
    "                #print(d_1)\n",
    "\n",
    "                d_2 = bag_of_words(map_ans_ner, unique_ner)\n",
    "                #print(d_2)\n",
    "                sub_matrix_df = eucli_matrix_df.loc[(unique_ner),(unique_ner)]\n",
    "                #print(sub_matrix_df)\n",
    "                sub_matrix= sub_matrix_df.as_matrix()\n",
    "                sub_matrix[np.isnan(sub_matrix)] = 0\n",
    "\n",
    "                #print(sub_matrix)\n",
    "                score = emd(d_1, d_2, sub_matrix)\n",
    "                #print(processed_sen_list[j])\n",
    "                #print('Score = ', score)\n",
    "                #l1 = [m,j,score] \n",
    "                #ls.append(pd.DataFrame([m,j,score])\n",
    "                #tagdis = pd.DataFrame(l1) \n",
    "                #tagdis['TagRank'] = tagdis.groupby('Qnno')['Tagdis'].rank(method = \"first\",ascending=True)\n",
    "                #Tagdistance.append(ls)\n",
    "                ls.append([m,j,score]) \n",
    "                \n",
    "                \n",
    "                \n",
    "                df = pd.DataFrame(ls,columns = ['Qnno','Sentno','TagDistance'])\n",
    "                \n",
    "                df['Rank'] = df.groupby('Qnno')['TagDistance'].rank(method = \"first\",ascending=True)\n",
    "\n",
    "        Tagdistance.append(df)\n",
    "    \n",
    "    #return Tagdistance\n",
    "                \n",
    "                #print([i,k,m,j,score])\n",
    "                \n",
    "               # print(\"****************************************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18896"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Tagdistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qnno</th>\n",
       "      <th>Sentno</th>\n",
       "      <th>TagDistance</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.378392</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.416877</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.378679</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.371880</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Qnno  Sentno  TagDistance  Rank\n",
       "0     0       0     0.378392   4.0\n",
       "1     0       1     0.349630   1.0\n",
       "2     0       2     0.416877   7.0\n",
       "3     0       3     0.378679   5.0\n",
       "4     0       4     0.371880   3.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tagdistance[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### W2V distance ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2vdistance = [] \n",
    "\n",
    "for i in range(len(sqd_data)):\n",
    "    paragraph_pointer = sqd_data.data[i]['paragraphs'] \n",
    "    \n",
    "\n",
    "    for k in range(len(paragraph_pointer)):\n",
    "        processed_sen_list, process_sen_tokenized_list = preprocess_text(paragraph_pointer[k]['context']) \n",
    "        processed_que_list = preprocess_question(paragraph_pointer[k]['qas'])\n",
    "        distance = [] \n",
    "        for m in range(len(processed_que_list)):\n",
    "            for j in range(len(processed_sen_list)):\n",
    "\n",
    "                #word2vec_model.init_sims(replace=True)\n",
    "                score = word2vec_model.wmdistance(processed_que_list[m].split(), processed_sen_list[j].split())\n",
    "                score_df = [m,j,score]\n",
    "                distance.append(score_df)\n",
    "                distance_df = pd.DataFrame(distance,columns = ['Qnno','Sentno','w2vDistance'])\n",
    "                distance_df['Rank'] = distance_df.groupby('Qnno')['w2vDistance'].rank(method = \"first\",ascending=True)\n",
    "        w2vdistance.append(distance_df)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18896"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2vdistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qnno</th>\n",
       "      <th>Sentno</th>\n",
       "      <th>w2vDistance</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.652292</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.631091</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.906310</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.734407</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.763077</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Qnno  Sentno  w2vDistance  Rank\n",
       "0     0       0     2.652292   3.0\n",
       "1     0       1     2.631091   2.0\n",
       "2     0       2     2.906310   7.0\n",
       "3     0       3     2.734407   5.0\n",
       "4     0       4     2.763077   6.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vdistance[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rankfun(df):\n",
    "    return list(df[df['Rank']==1.0]['Sentno']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagfirstrank = [] \n",
    "w2vfirstrank = [] \n",
    "\n",
    "for i in range(len(Tagdistance)):\n",
    "    tag = rankfun(Tagdistance[i])\n",
    "    w2v = rankfun(w2vdistance[i])\n",
    "    tagfirstrank.append(tag)\n",
    "    w2vfirstrank.append(w2v)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18896"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2vfirstrank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Qn-Actual ans ##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answerprocessfun(context):\n",
    "    answer_ls = [] \n",
    "    for i in range(len(context['qas'])):\n",
    "        #ls1 = []\n",
    "        #\n",
    "       # ls1.append(context['qas'][i]['answers'][0]['text'].lower().split())\n",
    "        answer_ls.append(context['qas'][i]['answers'][0]['text'].lower().split())\n",
    "    return answer_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commonsen(list1,list2):\n",
    "    return len(set(list1) & set(list2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qn_anssent = [] \n",
    "\n",
    "for b in range(len(sqd_data)):\n",
    "    #Content_list.append(b)                                 \n",
    "    \n",
    "    #Qn_list = [] \n",
    "    #Sentence_list = [] \n",
    "    paragraph_pointer = sqd_data.data[b]['paragraphs'] \n",
    "\n",
    "\n",
    "    for j in range(len(paragraph_pointer)):\n",
    "        processed_sen_list, process_sen_tokenized_list = preprocess_text(paragraph_pointer[j]['context']) \n",
    "        #processed_que_list = preprocess_question_second(paragraph_pointer[j]['qas'])\n",
    "        que_list = preprocess_question(paragraph_pointer[j]['qas'])\n",
    "        processed_ans_list = answerprocessfun(paragraph_pointer[j])\n",
    "\n",
    "        qn_ans_commonwords_list = np.zeros([len(processed_ans_list),len(process_sen_tokenized_list)])\n",
    "        for i in range(len(processed_ans_list)):\n",
    "                for j in range(len(process_sen_tokenized_list)):\n",
    "                    qn_ans_commonwords_list[i,j] = len(set(processed_ans_list[i]) & set(process_sen_tokenized_list[j][0]))\n",
    "                df = pd.DataFrame(qn_ans_commonwords_list)\n",
    "                df['AnsSent'] = df.T.idxmax()\n",
    "                df['Qnno'] = df.index \n",
    "        qn_anssent.append(df[['Qnno','AnsSent']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18896"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qn_anssent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_anssent = [] \n",
    "for i in range(len(qn_anssent)):\n",
    "    actual_anssent.append(list(qn_anssent[i]['AnsSent'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2, 1, 4, 1]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_anssent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zeronemapping(list1,list2):\n",
    "    mappinglist = [] \n",
    "    for i in range(len(list1)):\n",
    "        if (list1[i]==list2[i]):\n",
    "            mappinglist.append(1)\n",
    "        else:\n",
    "            mappinglist.append(0)\n",
    "    return mappinglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_mapping = [] \n",
    "w2v_mapping = [] \n",
    "for i in range(len(w2vfirstrank)):\n",
    "    w2v_mapping.append(zeronemapping(actual_anssent[i],w2vfirstrank[i])) \n",
    "    tag_mapping.append(zeronemapping(actual_anssent[i],tagfirstrank[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18896\n",
      "18896\n"
     ]
    }
   ],
   "source": [
    "print(len(w2v_mapping))\n",
    "print(len(tag_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Total Sentence number ###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn_actualans_df = pd.concat(qn_anssent)\n",
    "totalsen_no = len(qn_actualans_df)\n",
    "totalsen_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_accuracy = (sum([sum(l) for l in w2v_mapping])/totalsen_no)*100\n",
    "tag_accuracy = (sum([sum(l) for l in tag_mapping])/totalsen_no)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_distance accuracy  : 60.427630452402425 %\n",
      "tag_distance accuracy : 22.247970867247343 %\n"
     ]
    }
   ],
   "source": [
    "print(\"w2v_distance accuracy\", \" :\", w2v_accuracy,\"%\")\n",
    "print(\"tag_distance accuracy\",\":\",tag_accuracy,\"%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
